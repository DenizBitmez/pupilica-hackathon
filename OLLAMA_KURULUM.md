# Ollama ile AÃ§Ä±k KaynaklÄ± AI Kurulumu

## Ollama Nedir?

Ollama, bÃ¼yÃ¼k dil modellerini yerel olarak Ã§alÄ±ÅŸtÄ±rmanÄ±zÄ± saÄŸlayan aÃ§Ä±k kaynaklÄ± bir araÃ§tÄ±r. OpenAI'a alternatif olarak Ã¼cretsiz ve Ã¶zel modeller kullanabilirsiniz.

## Kurulum AdÄ±mlarÄ±

### 1. Ollama'yÄ± Ä°ndirin ve Kurun

**Windows iÃ§in:**
1. https://ollama.ai/download adresinden Windows sÃ¼rÃ¼mÃ¼nÃ¼ indirin
2. Ä°ndirilen dosyayÄ± Ã§alÄ±ÅŸtÄ±rÄ±n ve kurulumu tamamlayÄ±n
3. Kurulum sonrasÄ± Ollama otomatik olarak baÅŸlayacak

**Alternatif (PowerShell ile):**
```powershell
# Winget ile kurulum
winget install Ollama.Ollama

# Veya Chocolatey ile
choco install ollama
```

### 2. Model Ä°ndirin

Kurulum sonrasÄ± terminal/command prompt aÃ§Ä±n ve ÅŸu komutlarÄ± Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
# Temel sohbet modeli (7B parametre)
ollama pull llama2:7b

# Daha geliÅŸmiÅŸ model (13B parametre)
ollama pull llama2:13b

# Mistral modeli (daha hÄ±zlÄ±)
ollama pull mistral:7b

# Code modeli (kod yazma iÃ§in)
ollama pull codellama:7b

# TÃ¼rkÃ§e destekli model
ollama pull neural-chat:7b
```

### 3. Model Test Edin

```bash
# Modeli test et
ollama run llama2:7b

# Test mesajÄ±
>>> Merhaba, nasÄ±lsÄ±n?
```

### 4. Backend'i GÃ¼ncelleyin

```bash
cd backend
pip install -r requirements_huggingface.txt
```

### 5. Yeni Backend'i Ã‡alÄ±ÅŸtÄ±rÄ±n

```bash
python app_huggingface.py
```

## Ã–nerilen Modeller

### ğŸš€ HÄ±zlÄ± Modeller (7B parametre)
- `llama2:7b` - Genel amaÃ§lÄ±, iyi performans
- `mistral:7b` - HÄ±zlÄ± ve verimli
- `neural-chat:7b` - TÃ¼rkÃ§e destekli

### ğŸ§  GÃ¼Ã§lÃ¼ Modeller (13B+ parametre)
- `llama2:13b` - Daha iyi anlama
- `mistral:13b` - GeliÅŸmiÅŸ mantÄ±k
- `codellama:13b` - Kod yazma

### ğŸ’¡ Ã–zel Modeller
- `llama2-uncensored` - KÄ±sÄ±tlamasÄ±z
- `wizard-vicuna-uncensored` - DetaylÄ± yanÄ±tlar
- `orca-mini` - KÃ¼Ã§Ã¼k ama etkili

## Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Model | Boyut | RAM | HÄ±z | Kalite |
|-------|-------|-----|-----|--------|
| llama2:7b | 3.8GB | 8GB | â­â­â­â­ | â­â­â­ |
| llama2:13b | 7.3GB | 16GB | â­â­â­ | â­â­â­â­ |
| mistral:7b | 4.1GB | 8GB | â­â­â­â­â­ | â­â­â­â­ |
| neural-chat:7b | 3.8GB | 8GB | â­â­â­â­ | â­â­â­ |

## Avantajlar

### âœ… Ollama AvantajlarÄ±
- **Ãœcretsiz**: HiÃ§bir API Ã¼creti yok
- **Gizlilik**: Verileriniz yerel kalÄ±r
- **Ã–zelleÅŸtirilebilir**: Ä°stediÄŸiniz modeli kullanÄ±n
- **Offline**: Ä°nternet baÄŸlantÄ±sÄ± olmadan Ã§alÄ±ÅŸÄ±r
- **HÄ±zlÄ±**: Yerel iÅŸlem gÃ¼cÃ¼

### âŒ Dezavantajlar
- **RAM Gereksinimi**: En az 8GB RAM gerekli
- **Ä°lk Kurulum**: Model indirme sÃ¼resi
- **DonanÄ±m**: GPU olmadan yavaÅŸ olabilir

## GPU DesteÄŸi

### NVIDIA GPU
```bash
# CUDA desteÄŸi iÃ§in
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### AMD GPU
```bash
# ROCm desteÄŸi iÃ§in
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.4.2
```

## Sorun Giderme

### Model Ä°ndirme HatasÄ±
```bash
# Ollama servisini yeniden baÅŸlat
ollama serve

# Modeli tekrar indir
ollama pull llama2:7b
```

### RAM YetersizliÄŸi
- Daha kÃ¼Ã§Ã¼k model kullanÄ±n (`llama2:7b`)
- DiÄŸer uygulamalarÄ± kapatÄ±n
- Virtual memory artÄ±rÄ±n

### YavaÅŸ YanÄ±t
- GPU kullanÄ±n
- Daha kÃ¼Ã§Ã¼k model seÃ§in
- `num_predict` deÄŸerini azaltÄ±n

## Maliyet KarÅŸÄ±laÅŸtÄ±rmasÄ±

### OpenAI GPT-3.5
- **Maliyet**: ~$0.002 per 1K token
- **AylÄ±k tahmini**: $50-200
- **BaÄŸÄ±mlÄ±lÄ±k**: Ä°nternet + API key

### Ollama (Yerel)
- **Maliyet**: Sadece elektrik
- **AylÄ±k tahmini**: $5-15
- **BaÄŸÄ±mlÄ±lÄ±k**: Sadece donanÄ±m

## SonuÃ§

Ollama ile **%90 maliyet tasarrufu** saÄŸlayabilir ve tamamen Ã¶zel bir AI asistanÄ±nÄ±z olabilir! ğŸ‰

**Ã–nerilen BaÅŸlangÄ±Ã§:**
1. `llama2:7b` modelini indirin
2. Backend'i gÃ¼ncelleyin
3. Test edin ve beÄŸendiÄŸiniz modeli seÃ§in
