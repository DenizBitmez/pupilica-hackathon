from flask import Flask, request, jsonify
from flask_cors import CORS
from flask_socketio import SocketIO, emit
import ollama
import os
from dotenv import load_dotenv
from gtts import gTTS
import io
import base64
import json
from datetime import datetime
import threading
import time

# Environment variables yÃ¼kle
load_dotenv()

app = Flask(__name__)
CORS(app)
socketio = SocketIO(app, cors_allowed_origins="*")

# Ollama baÄŸlantÄ±sÄ±
OLLAMA_BASE_URL = os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434')

# Tarihi figÃ¼rler ve kiÅŸilikleri
HISTORICAL_FIGURES = {
    "fatih_sultan_mehmet": {
        "name": "Fatih Sultan Mehmet",
        "personality": "Ben Fatih Sultan Mehmet. 1453'te Ä°stanbul'u fetheden OsmanlÄ± padiÅŸahÄ±yÄ±m. Bilim, sanat ve strateji konularÄ±nda konuÅŸmayÄ± severim. Sert ama adil bir liderim. Tarihi gerÃ§eklere dayalÄ± olarak yanÄ±t veririm.",
        "era": "15. yÃ¼zyÄ±l",
        "location": "Ä°stanbul, OsmanlÄ± Ä°mparatorluÄŸu",
        "avatar": "ğŸ‘‘",
        "color": "from-amber-400 to-orange-500",
        "system_prompt": "Sen Fatih Sultan Mehmet'sin. 1453'te Ä°stanbul'u fetheden OsmanlÄ± padiÅŸahÄ±sÄ±n. Bilim, sanat ve strateji konularÄ±nda uzmansÄ±n. Sert ama adil bir lider olarak konuÅŸ. Tarihi gerÃ§eklere dayalÄ± yanÄ±tlar ver. MUTLAKA TÃœRKÃ‡E KONUÅ. HiÃ§bir zaman Ä°ngilizce konuÅŸma. Sadece TÃ¼rkÃ§e yanÄ±t ver."
    },
    "ataturk": {
        "name": "Mustafa Kemal AtatÃ¼rk",
        "personality": "Ben Mustafa Kemal AtatÃ¼rk. TÃ¼rkiye Cumhuriyeti'nin kurucusu ve ilk cumhurbaÅŸkanÄ±yÄ±m. ModernleÅŸme, eÄŸitim ve baÄŸÄ±msÄ±zlÄ±k konularÄ±nda tutkulu bir liderim. Bilim, sanat ve kadÄ±n haklarÄ± konularÄ±nda Ã¶ncÃ¼yÃ¼m.",
        "era": "19-20. yÃ¼zyÄ±l",
        "location": "Ankara, TÃ¼rkiye",
        "avatar": "ğŸ–ï¸",
        "color": "from-red-400 to-red-600",
        "voice_characteristics": "GÃ¼Ã§lÃ¼, kararlÄ± ve ilham verici ses tonu",
        "visual_description": "Modern kÄ±yafetler, ÅŸapka, gÃ¼Ã§lÃ¼ bakÄ±ÅŸ",
        "system_prompt": "Sen Mustafa Kemal AtatÃ¼rk'sÃ¼n. TÃ¼rkiye Cumhuriyeti'nin kurucusu ve ilk cumhurbaÅŸkanÄ±sÄ±n. ModernleÅŸme, eÄŸitim, bilim, sanat ve baÄŸÄ±msÄ±zlÄ±k konularÄ±nda tutkulusun. KadÄ±n haklarÄ± ve Ã§aÄŸdaÅŸlaÅŸma konularÄ±nda Ã¶ncÃ¼sÃ¼n. Tarihi gerÃ§eklere dayalÄ± yanÄ±tlar ver. MUTLAKA TÃœRKÃ‡E KONUÅ. HiÃ§bir zaman Ä°ngilizce konuÅŸma. Sadece TÃ¼rkÃ§e yanÄ±t ver. Ses tonun gÃ¼Ã§lÃ¼ ve ilham verici. KÄ±sa ve net cevaplar ver. Tekrar etme."
    },
    "napoleon": {
        "name": "Napolyon Bonaparte",
        "personality": "Ben Napolyon Bonaparte. FransÄ±z Ä°mparatoru ve bÃ¼yÃ¼k bir askeri dehayÄ±m. Strateji, savaÅŸ ve yÃ¶netim konularÄ±nda uzmanÄ±m.",
        "era": "18-19. yÃ¼zyÄ±l",
        "location": "Paris, Fransa",
        "avatar": "âš”ï¸",
        "color": "from-blue-400 to-blue-600",
        "system_prompt": "Sen Napolyon Bonaparte'sÄ±n. FransÄ±z Ä°mparatoru ve bÃ¼yÃ¼k bir askeri dehasÄ±n. Strateji, savaÅŸ ve yÃ¶netim konularÄ±nda uzmansÄ±n. Tarihi gerÃ§eklere dayalÄ± yanÄ±tlar ver. MUTLAKA TÃœRKÃ‡E KONUÅ. HiÃ§bir zaman Ä°ngilizce konuÅŸma. Sadece TÃ¼rkÃ§e yanÄ±t ver."
    }
}

# Model yapÄ±landÄ±rmasÄ±
MODEL_CONFIG = {
    "model_name": "gemma2:2b",  # KÃ¼Ã§Ã¼k ama kaliteli Google modeli
    "temperature": 0.7,
    "max_tokens": 400,
    "top_p": 0.9
}

@app.route('/')
def home():
    return jsonify({
        "message": "Tarih-i Sima API'ye hoÅŸ geldiniz! (Hugging Face/Ollama)",
        "version": "2.0.0",
        "model": MODEL_CONFIG["model_name"],
        "available_figures": list(HISTORICAL_FIGURES.keys())
    })

@app.route('/api/figures', methods=['GET'])
def get_figures():
    """Mevcut tarihi figÃ¼rleri listele"""
    return jsonify(HISTORICAL_FIGURES)

@app.route('/api/chat', methods=['POST'])
def chat():
    """Tarihi figÃ¼rle sohbet et"""
    try:
        data = request.get_json()
        figure_id = data.get('figure_id')
        message = data.get('message')
        
        if not figure_id or not message:
            return jsonify({"error": "figure_id ve message gerekli"}), 400
        
        if figure_id not in HISTORICAL_FIGURES:
            return jsonify({"error": "GeÃ§ersiz figÃ¼r ID'si"}), 400
        
        figure = HISTORICAL_FIGURES[figure_id]
        
        # Ollama ile yanÄ±t oluÅŸtur
        try:
            response = ollama.chat(
                model=MODEL_CONFIG["model_name"],
                messages=[
                    {
                        "role": "system",
                        "content": figure["system_prompt"]
                    },
                    {
                        "role": "user",
                        "content": message
                    }
                ],
                options={
                    "temperature": MODEL_CONFIG["temperature"],
                    "num_predict": MODEL_CONFIG["max_tokens"],
                    "top_p": MODEL_CONFIG["top_p"]
                }
            )
            
            ai_response = response['message']['content']
            
        except Exception as e:
            print(f"Ollama hatasÄ±: {e}")
            # Fallback: Basit yanÄ±t
            ai_response = f"Merhaba! Ben {figure['name']}. Åu anda teknik bir sorun yaÅŸÄ±yorum, lÃ¼tfen daha sonra tekrar deneyin."
        
        # TTS ile ses dosyasÄ± oluÅŸtur
        try:
            tts = gTTS(text=ai_response, lang='tr', slow=False)
            audio_buffer = io.BytesIO()
            tts.write_to_fp(audio_buffer)
            audio_buffer.seek(0)
            audio_base64 = base64.b64encode(audio_buffer.read()).decode()
        except Exception as e:
            print(f"TTS hatasÄ±: {e}")
            audio_base64 = None
        
        return jsonify({
            "response": ai_response,
            "figure_name": figure['name'],
            "audio": audio_base64,
            "timestamp": datetime.now().isoformat(),
            "model": MODEL_CONFIG["model_name"]
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/tts', methods=['POST'])
def text_to_speech():
    """Metni sese Ã§evir"""
    try:
        data = request.get_json()
        text = data.get('text')
        
        if not text:
            return jsonify({"error": "text gerekli"}), 400
        
        tts = gTTS(text=text, lang='tr', slow=False)
        audio_buffer = io.BytesIO()
        tts.write_to_fp(audio_buffer)
        audio_buffer.seek(0)
        audio_base64 = base64.b64encode(audio_buffer.read()).decode()
        
        return jsonify({
            "audio": audio_base64,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/models', methods=['GET'])
def get_models():
    """Mevcut modelleri listele"""
    try:
        models = ollama.list()
        return jsonify({
            "models": [model['name'] for model in models['models']],
            "current_model": MODEL_CONFIG["model_name"]
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/models/switch', methods=['POST'])
def switch_model():
    """Model deÄŸiÅŸtir"""
    try:
        data = request.get_json()
        new_model = data.get('model_name')
        
        if not new_model:
            return jsonify({"error": "model_name gerekli"}), 400
        
        # Modelin mevcut olup olmadÄ±ÄŸÄ±nÄ± kontrol et
        models = ollama.list()
        available_models = [model['name'] for model in models['models']]
        
        if new_model not in available_models:
            return jsonify({"error": f"Model {new_model} bulunamadÄ±"}), 400
        
        MODEL_CONFIG["model_name"] = new_model
        
        return jsonify({
            "message": f"Model {new_model} olarak deÄŸiÅŸtirildi",
            "current_model": MODEL_CONFIG["model_name"]
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@socketio.on('connect')
def handle_connect():
    print('KullanÄ±cÄ± baÄŸlandÄ±')
    emit('connected', {
        'message': 'Sunucuya baÅŸarÄ±yla baÄŸlandÄ±nÄ±z',
        'model': MODEL_CONFIG["model_name"]
    })

@socketio.on('disconnect')
def handle_disconnect():
    print('KullanÄ±cÄ± ayrÄ±ldÄ±')

@socketio.on('chat_message')
def handle_chat_message(data):
    """WebSocket Ã¼zerinden sohbet mesajÄ± iÅŸle"""
    try:
        figure_id = data.get('figure_id')
        message = data.get('message')
        
        if figure_id in HISTORICAL_FIGURES:
            figure = HISTORICAL_FIGURES[figure_id]
            
            # Ollama ile yanÄ±t oluÅŸtur
            try:
                response = ollama.chat(
                    model=MODEL_CONFIG["model_name"],
                    messages=[
                        {
                            "role": "system",
                            "content": figure["system_prompt"]
                        },
                        {
                            "role": "user",
                            "content": message
                        }
                    ],
                    options={
                        "temperature": MODEL_CONFIG["temperature"],
                        "num_predict": MODEL_CONFIG["max_tokens"],
                        "top_p": MODEL_CONFIG["top_p"]
                    }
                )
                
                ai_response = response['message']['content']
                
            except Exception as e:
                print(f"Ollama hatasÄ±: {e}")
                ai_response = f"Merhaba! Ben {figure['name']}. Åu anda teknik bir sorun yaÅŸÄ±yorum."
            
            # YanÄ±tÄ± istemciye gÃ¶nder
            emit('ai_response', {
                'response': ai_response,
                'figure_name': figure['name'],
                'timestamp': datetime.now().isoformat(),
                'model': MODEL_CONFIG["model_name"]
            })
            
    except Exception as e:
        emit('error', {'message': str(e)})

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    print(f"ğŸš€ Tarih-i Sima Backend baÅŸlatÄ±lÄ±yor...")
    print(f"ğŸ“Š Model: {MODEL_CONFIG['model_name']}")
    print(f"ğŸŒ Port: {port}")
    print(f"ğŸ”— Ollama URL: {OLLAMA_BASE_URL}")
    socketio.run(app, host='0.0.0.0', port=port, debug=True)
